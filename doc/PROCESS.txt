==================================================================================
 The Tokyo Project is hosted on Sourceforge:
 http://sourceforge.net/projects/tokyo/
 
 Copyright (c) 2005-2007 Eric Bréchemier
 http://eric.brechemier.name
 Licensed under BSD License and/or MIT License.
 See: http://creativecommons.org/licenses/BSD/
==================================================================================

==========================================
Title: Tokyo Project - Process Definition
Last modified: 2007-12-19
By: Eric Bréchemier
Encoding: UTF-8
==========================================

                        *******************************   
                        **       Tokyo Project       **
                        **     Process Definition    **
                        *******************************


* OBJECTIVES
- provide an XML view of non-XML data
- let applications view and create non-XML documents as easily as XML ones
- transformation of non-XML documents to XML and back again

* VISION
- we start with:
    - on the one hand, lots of existing applications working on xml data,
      lots of developers with experience in xml processing,
    - on the other hand, many remaining non-xml formats
      (e.g. for pure binary or pure text data)

- handling non-XML data as XML requires two transformations:
    - from non-xml to xml, for applications input,
    corresponding to XML parsing
    - from xml to non-xml, for applications output,
    corresponding to XML serialization

- an XML parser works on standard XML files/data and implements some XML Parser API (DOM, SAX,...)
  Applications do not access XML data directly, but through the provided API
  
- an XML serializer implements some XML Serializer API (DOM,XML Pull,StAX...).
  Applications often do not create XML data directly, but through the provided API.
  Some applications create XML data directly - this data will have to be converted in a second step.
    
- the structure of an XML document is explicit, it uses the same syntax for all XML documents,
  no matter which grammar/vocabulary they use. Parsers can process this data without any knowledge
  of the document semantics.
  Structure in non-XML data is often implicit or uses a very specific syntax.
  Applications often need to know some grammar to be able to parse the data.

* A SAMPLE SIMPLE PROCESS
Enough concepts! Let me introduce a simple sample process, or a sample simple process if you prefer,
applied to the first prototype: How to sort CSV records using XSLT.

We will grow a working prototype step by step, using an iterative process. You can refer to the files 
of this example in the folder "prototype-1-csv2xml" of Tokyo Project download.

The first step will be to write the main loop, which we call ProtoOneMainLoop because it is the 
Prototype One, and it is the main loop.

[[WORK IN PROGRESS]]


* FUTURE DIRECTION: AUTOMATION USING GRAMMAR DEFINITIONS
  Inspired by the example of compiler program generation based on grammar definition,
  I am quite convinced that the same could prove useful, given appropriate required 
  adaptations, to transform data, e.g. to get an XML view of binary data:
  
  - define the grammar of your data
  - define the vocabulary for your data viewed as XML
  - define the syntax of your queries, e.g. the required XPath subset
  - use them to create 
      - one tool reading your data and implementing an XML parsing API,
        with the following possible components:
        * Query parsing and analysis
        * State Machine for Data Grammar
        * State Machine/Factory for Data Extraction
        
      - one tool providing an XML serializing API and writing your data,
        with the following possible components:
        * Query parsing and analysis
        * State Machine for Data Grammar
        * State Machine/Factory for Data Serialization
      
      - and maybe additional tools to validate input data / generated data
      
  - plug your tool on applications processing XML

  NOTE:
    - you may need some adapters for the expected API or extra conversion steps
    - the application has to know the vocabulary of your data viewed as XML 
      to understand its semantic
  
  At the core lies the need to formalize the grammar of your data, which could be done with 
  several to be determined notations (EBNF, tables, encoding algorithm,...). I mean here that 
  the tool should be extensible to support several grammars, not be limitated to a single one.
  
  Adapted to handle binary data and not just text and character tokens, the grammar should define:
    - some structure, which will be mapped to the XML tree structure
    - some codecs, defining the format of leaf nodes
    - some comments, explaining the semantics of different fields
    - there may also be some additional relations between different elements,
    that must be understood for proper decoding (choice, repeat, based on values read before)
  
  This project may end up defining a general format good enough for 80% of grammar definitions,
  or using different grammar types for different formats.
        
=============== END OF DOCUMENT: Tokyo Project - Process ===============